@INPROCEEDINGS{unsw_comparison,
author={N. Moustafa and J. Slay},
booktitle={2015 4th International Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (BADGERS)},
title={The Significant Features of the UNSW-NB15 and the KDD99 Data Sets for Network Intrusion Detection Systems},
year={2015},
volume={},
number={},
pages={25-31},
keywords={computer network security;data mining;feature selection;telecommunication traffic;FAR;KDD99 data sets;NIDS;UNSW-NB15 datasets;association rule mining algorithm;cyber-attack pattern detection;false alarm rate;feature selection;network intrusion detection systems;network packets;network traffic flow;ubiquitous services;Complexity theory;Computers;Data mining;Feature extraction;Security;Testing;Training;Feature extraction;Feature selection;KDD99 dataset;Network Intrusion Detection System (NIDS);UNSW-NB15 dataset},
doi={10.1109/BADGERS.2015.014},
ISSN={},
month={Nov},}

@INPROCEEDINGS{unsw15,
author={N. Moustafa and J. Slay},
booktitle={2015 Military Communications and Information Systems Conference (MilCIS)},
title={UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)},
year={2015},
volume={},
number={},
pages={1-6},
keywords={computer network security;telecommunication traffic;UNSW-NB15 network data set;network intrusion detection systems;network traffic;Benchmark testing;Data models;Feature extraction;IP networks;Servers;Telecommunication traffic;Training;NIDS;UNSW-NB15 data set;low footprint attacks;pcap files;testbed},
doi={10.1109/MilCIS.2015.7348942},
ISSN={},
month={Nov},}

@INPROCEEDINGS{kdd99,
author={M. Tavallaee and E. Bagheri and W. Lu and A. A. Ghorbani},
booktitle={2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications},
title={A detailed analysis of the KDD CUP 99 data set},
year={2009},
volume={},
number={},
pages={1-6},
keywords={security of data;statistical analysis;KDD CUP 99 data set analysis;anomaly detection;attack detection;signature-based intrusion detection system;statistical analysis;Application software;Computational intelligence;Computer aided manufacturing;Computer networks;Computer security;Data security;Intrusion detection;Learning systems;Statistical analysis;Testing},
doi={10.1109/CISDA.2009.5356528},
ISSN={2329-6267},
month={July},}

@article{kmeans_15,
title = "Using Data Mining Algorithms for Developing a Model for Intrusion Detection System (IDS)",
journal = "Procedia Computer Science",
volume = "61",
pages = "46 - 51",
year = "2015",
note = "Complex Adaptive Systems San Jose, CA November 2-4, 2015",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.09.145",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915029750",
author = "Solane Duque and Mohd. Nizam bin Omar",
keywords = "data mining, clustering, machine learning, unsupervised learning, k-means"
}

@INPROCEEDINGS{mlp_17,
author={P. V. S. Alpa√±o and J. R. I. Pedrasa and R. Atienza},
booktitle={TENCON 2017 - 2017 IEEE Region 10 Conference},
title={Multilayer perceptron with binary weights and activations for intrusion detection of Cyber-Physical systems},
year={2017},
volume={},
number={},
pages={2825-2829},
keywords={cyber-physical systems;multilayer perceptrons;security of data;CPS;binary weights;cyber-attacks;cyber-physical systems;host-centric intrusion detection;multilayer perceptron neural network;Binary Weights;CPS;Cyber Attacks;Intrusion Detection;Multilayer Perceptron;Theano},
doi={10.1109/TENCON.2017.8228342},
ISSN={},
month={Nov},}

@Article{ids_taxonomy,
author="Debar, Herv{\'e}
and Dacier, Marc
and Wespi, Andreas",
title="A revised taxonomy for intrusion-detection systems",
journal="Annales Des T{\'e}l{\'e}communications",
year="2000",
month="Jul",
day="01",
volume="55",
number="7",
pages="361--378",
issn="1958-9395",
doi="10.1007/BF02994844",
url="https://doi.org/10.1007/BF02994844"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@unknown{nb_optimal,
author = {Zhang, Harry},
year = {2004},
month = {January},
pages = {},
title = {The Optimality of Naive Bayes},
volume = {2},
booktitle = {Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004}
}

@INPROCEEDINGS{random_forest,
author={Tin Kam Ho},
booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition},
title={Random decision forests},
year={1995},
volume={1},
number={},
pages={278-282 vol.1},
keywords={decision theory;handwriting recognition;optical character recognition;complexity;decision trees;generalization accuracy;handwritten digits;random decision forests;stochastic modeling;suboptimal accuracy;tree-based classifiers;Classification tree analysis;Decision trees;Handwriting recognition;Hidden Markov models;Multilayer perceptrons;Optimization methods;Stochastic processes;Testing;Tin;Training data},
doi={10.1109/ICDAR.1995.598994},
ISSN={},
month={Aug},}

@Article{extra_tree,
author="Geurts, Pierre
and Ernst, Damien
and Wehenkel, Louis",
title="Extremely randomized trees",
journal="Machine Learning",
year="2006",
month="Apr",
day="01",
volume="63",
number="1",
pages="3--42",
abstract="This paper proposes a new tree-based ensemble method for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.",
issn="1573-0565",
doi="10.1007/s10994-006-6226-1",
url="https://doi.org/10.1007/s10994-006-6226-1"
}
